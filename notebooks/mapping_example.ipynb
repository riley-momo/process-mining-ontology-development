{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import os\n",
    "import yatter\n",
    "from ruamel.yaml import YAML\n",
    "import kglab\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths\n",
    "data_dir = '../data'\n",
    "output_dir = '../output'\n",
    "config_dir = '../config'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "mapping_file = data_dir + '/sample_mapping.yaml'\n",
    "rml_output_path = output_dir + '/sample_mapping_rml.ttl'\n",
    "kg_config_path = config_dir + '/sample_kg_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define KGLab config\n",
    "config = f\"\"\"\n",
    "[test]\n",
    "mappings={rml_output_path}\n",
    "\"\"\"\n",
    "with open(kg_config_path, 'w') as f:\n",
    "    f.write(config)\n",
    "# define KG namespaces   \n",
    "namespaces = {\n",
    "    'ex:' : \"http://example.com/\",\n",
    "    'on:' : \"https://stl.mie.utoronto.ca/ontologies/spm/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_log(log_path):\n",
    "  \"\"\"\n",
    "  Return a dataframe from a given XES log filepath or CSV\n",
    "  \"\"\"\n",
    "  if any(log_path.lower().endswith(ext) for ext in ['.xes', '.xes.gz']):\n",
    "    log = pm4py.read_xes(log_path)\n",
    "    df = pm4py.convert_to_dataframe(log)\n",
    "  elif log_path.lower().endswith('.csv'):\n",
    "    df = pd.read_csv(log_path)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseID</th>\n",
       "      <th>activityID</th>\n",
       "      <th>eventID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>resourceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_0</td>\n",
       "      <td>activity_A</td>\n",
       "      <td>event_0</td>\n",
       "      <td>2016-01-01 09:00:00.000000+00:00</td>\n",
       "      <td>user_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_0</td>\n",
       "      <td>activity_A</td>\n",
       "      <td>event_1</td>\n",
       "      <td>2016-01-01 09:15:00.000000+00:00</td>\n",
       "      <td>user_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_0</td>\n",
       "      <td>activity_C</td>\n",
       "      <td>event_2</td>\n",
       "      <td>2016-01-01 09:35:00.000000+00:00</td>\n",
       "      <td>user_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_1</td>\n",
       "      <td>activity_A</td>\n",
       "      <td>event_3</td>\n",
       "      <td>2016-01-02 09:00:00.000000+00:00</td>\n",
       "      <td>user_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_1</td>\n",
       "      <td>activity_B</td>\n",
       "      <td>event_4</td>\n",
       "      <td>2016-01-02 09:00:00.000000+00:00</td>\n",
       "      <td>user_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseID  activityID  eventID                         timestamp resourceID\n",
       "0  case_0  activity_A  event_0  2016-01-01 09:00:00.000000+00:00     user_1\n",
       "1  case_0  activity_A  event_1  2016-01-01 09:15:00.000000+00:00     user_1\n",
       "2  case_0  activity_C  event_2  2016-01-01 09:35:00.000000+00:00     user_1\n",
       "3  case_1  activity_A  event_3  2016-01-02 09:00:00.000000+00:00     user_1\n",
       "4  case_1  activity_B  event_4  2016-01-02 09:00:00.000000+00:00     user_0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the sample event log\n",
    "log_df = load_df_from_log('../data/sample_log.csv')\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 20:09:21,473 | INFO: Translating YARRRML mapping to [R2]RML\n",
      "2024-07-29 20:09:21,474 | INFO: RML content is created!\n",
      "2024-07-29 20:09:21,486 | INFO: Mapping has been syntactically validated.\n",
      "2024-07-29 20:09:21,488 | INFO: Translation has finished successfully.\n"
     ]
    }
   ],
   "source": [
    "## convert YARRRML to RML\n",
    "yaml = YAML(typ='safe', pure=True)\n",
    "yarrrml_content = yaml.load(open(mapping_file))\n",
    "rml_content = yatter.translate(yarrrml_content)\n",
    "rml_file = open(rml_output_path, 'w')\n",
    "rml_file.write(rml_content)\n",
    "rml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 20:09:21,518 | DEBUG: CONFIGURATION: {'output_file': 'knowledge-graph', 'na_values': ',nan', 'safe_percent_encoding': '', 'read_parsed_mappings_path': '', 'write_parsed_mappings_path': '', 'mapping_partitioning': 'PARTIAL-AGGREGATIONS', 'logging_file': '', 'oracle_client_lib_dir': '', 'oracle_client_config_dir': '', 'udfs': '', 'output_dir': '', 'output_format': 'N-TRIPLES', 'only_printable_chars': 'no', 'infer_sql_datatypes': 'no', 'logging_level': 'INFO', 'number_of_processes': '24'}\n",
      "2024-07-29 20:09:21,519 | DEBUG: DATA SOURCE `test`: {'mappings': '../output/sample_mapping_rml.ttl'}\n",
      "2024-07-29 20:09:22,212 | INFO: 8 mapping rules retrieved.\n",
      "2024-07-29 20:09:22,222 | DEBUG: All predicate maps are constant-valued, invariant subset is not enforced.\n",
      "2024-07-29 20:09:22,227 | DEBUG: All graph maps are constant-valued, invariant subset is not enforced.\n",
      "2024-07-29 20:09:22,231 | INFO: Mapping partition with 8 groups generated.\n",
      "2024-07-29 20:09:22,233 | INFO: Maximum number of rules within mapping group: 1.\n",
      "2024-07-29 20:09:22,234 | INFO: Mappings processed in 0.708 seconds.\n",
      "2024-07-29 20:09:22,237 | DEBUG: Parallelizing with 24 cores.\n",
      "2024-07-29 20:09:22,562 | INFO: Number of triples generated in total: 60.\n"
     ]
    }
   ],
   "source": [
    "# init knowledge graph\n",
    "kg = kglab.KnowledgeGraph(name=\"event-log-sample\", namespaces=namespaces)\n",
    "# create instances from mapping\n",
    "kg.materialize('config.ini')\n",
    "# save rdf instances\n",
    "kg.save_rdf(output_dir + '/sample_log_instances.ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert from RDF A-Box to PSL A-Box\n",
    "ABox = np.array([])\n",
    "\n",
    "## Query1: Simple unary predicates\n",
    "df = kg.query_as_df(sparql=\"SELECT ?s ?o WHERE {?s a ?o}\")\n",
    "unary_preds = df.apply(lambda x: re.sub(r'.*:', '', x['o']) + '(' + re.sub(r'.*/|>$', '', x['s']) + ')', axis=1).values\n",
    "ABox = np.concatenate((ABox, unary_preds), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 2: Timepoints\n",
    "df = kg.query_as_df(sparql=\"SELECT ?s ?t WHERE {?s ns1:hasRecordedTime ?t}\")\n",
    "unique_timestamps = df['t'].unique()\n",
    "\n",
    "# create timestamp mapping\n",
    "timestamp_mapping = {timestamp: f'ts_{i}' for i, timestamp in enumerate(sorted(unique_timestamps))}\n",
    "\n",
    "# apply mapping\n",
    "df['new_t'] = df['t'].map(timestamp_mapping)\n",
    "\n",
    "# create ordering relations over timestamps\n",
    "unique_mapped_timestamps = sorted(df['new_t'].unique())\n",
    "timestamp_pairs = [(unique_mapped_timestamps[i], unique_mapped_timestamps[i+1]) for i in range(len(unique_mapped_timestamps) - 1)]\n",
    "\n",
    "before_relations = [f'before({t1},{t2})' for t1, t2 in timestamp_pairs]\n",
    "\n",
    "timestamp_preds = [f'timepoint({t})' for t in unique_mapped_timestamps]\n",
    "\n",
    "event_timings = df.apply(lambda x: 'hasRecordedTime({}, {})'.format(re.sub(r\".*/|>$\", '', x[\"s\"]), x[\"new_t\"]), axis=1).values\n",
    "\n",
    "ABox = np.concatenate((ABox, timestamp_preds, event_timings, before_relations), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 3: Other binary relations\n",
    "df = kg.query_as_df(sparql=\"SELECT ?s ?p ?o WHERE {?s ?p ?o . FILTER (?p != rdf:type && ?p != ns1:hasRecordedTime)}\")\n",
    "binary_relations = df.apply(lambda x: f'{re.sub(r\".*:\", \"\", x[\"p\"])}({re.sub(r\".*/|>$\", \"\", x[\"s\"])}, {re.sub(r\".*/|>$\", \"\", x[\"o\"])})', axis=1).values\n",
    "\n",
    "ABox = np.concatenate((ABox, binary_relations), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lastly, add process instance relations\n",
    "df = kg.query_as_df(sparql=\"SELECT ?s WHERE {?s a ns1:Event}\")\n",
    "process_instance = df.apply(lambda x: f'hasProcess({re.sub(r\".*/|>$\", \"\", x[\"s\"])}, P1)', axis=1).values\n",
    "process_instance\n",
    "\n",
    "ABox = np.concatenate((ABox, process_instance), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Resource(user_0)', 'Resource(user_1)', 'Resource(user_2)',\n",
       "       'Event(event_3)', 'Event(event_6)', 'Event(event_1)',\n",
       "       'Event(event_2)', 'Event(event_9)', 'Event(event_7)',\n",
       "       'Event(event_4)', 'Event(event_5)', 'Event(event_8)',\n",
       "       'Event(event_0)', 'Case(case_0)', 'Case(case_2)', 'Case(case_1)',\n",
       "       'Activity(activity_C)', 'Activity(activity_B)',\n",
       "       'Activity(activity_A)', 'Activity(activity_D)', 'timepoint(ts_0)',\n",
       "       'timepoint(ts_1)', 'timepoint(ts_2)', 'timepoint(ts_3)',\n",
       "       'timepoint(ts_4)', 'timepoint(ts_5)', 'timepoint(ts_6)',\n",
       "       'hasRecordedTime(event_3, ts_4)', 'hasRecordedTime(event_4, ts_4)',\n",
       "       'hasRecordedTime(event_8, ts_2)', 'hasRecordedTime(event_1, ts_2)',\n",
       "       'hasRecordedTime(event_2, ts_3)', 'hasRecordedTime(event_7, ts_1)',\n",
       "       'hasRecordedTime(event_6, ts_0)', 'hasRecordedTime(event_0, ts_0)',\n",
       "       'hasRecordedTime(event_5, ts_5)', 'hasRecordedTime(event_9, ts_6)',\n",
       "       'before(ts_0,ts_1)', 'before(ts_1,ts_2)', 'before(ts_2,ts_3)',\n",
       "       'before(ts_3,ts_4)', 'before(ts_4,ts_5)', 'before(ts_5,ts_6)',\n",
       "       'hasCase(event_4, case_1)', 'hasActivity(event_5, activity_C)',\n",
       "       'hasResource(event_7, user_1)', 'hasActivity(event_3, activity_A)',\n",
       "       'hasActivity(event_7, activity_B)',\n",
       "       'hasActivity(event_8, activity_C)', 'hasCase(event_5, case_1)',\n",
       "       'hasCase(event_0, case_0)', 'hasResource(event_5, user_0)',\n",
       "       'hasResource(event_8, user_2)', 'hasResource(event_3, user_1)',\n",
       "       'hasCase(event_6, case_2)', 'hasCase(event_3, case_1)',\n",
       "       'hasResource(event_0, user_1)', 'hasCase(event_2, case_0)',\n",
       "       'hasResource(event_4, user_0)', 'hasCase(event_9, case_2)',\n",
       "       'hasActivity(event_0, activity_A)', 'hasResource(event_2, user_1)',\n",
       "       'hasCase(event_8, case_2)', 'hasCase(event_1, case_0)',\n",
       "       'hasCase(event_7, case_2)', 'hasResource(event_6, user_1)',\n",
       "       'hasResource(event_1, user_1)', 'hasResource(event_9, user_1)',\n",
       "       'hasActivity(event_4, activity_B)',\n",
       "       'hasActivity(event_1, activity_A)',\n",
       "       'hasActivity(event_2, activity_C)',\n",
       "       'hasActivity(event_6, activity_A)',\n",
       "       'hasActivity(event_9, activity_D)', 'hasProcess(event_3, P1)',\n",
       "       'hasProcess(event_6, P1)', 'hasProcess(event_1, P1)',\n",
       "       'hasProcess(event_2, P1)', 'hasProcess(event_9, P1)',\n",
       "       'hasProcess(event_7, P1)', 'hasProcess(event_4, P1)',\n",
       "       'hasProcess(event_5, P1)', 'hasProcess(event_8, P1)',\n",
       "       'hasProcess(event_0, P1)'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ABox to file\n",
    "with open(output_dir + '/sample_log_ABox.clif', 'w') as f:\n",
    "    for item in ABox:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
